{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using Pkg\n",
    "Pkg.activate(\".\")\n",
    "using JSON\n",
    "using WordTokenizers\n",
    "using StatsBase\n",
    "using Flux,CuArrays\n",
    "using Flux:onehot\n",
    "using Base.Iterators:partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"../data/\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"utils.jl\")\n",
    "BASE_PATH = \"../data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Array{Any,1}:\n",
       " (\"<s> A very clean and well decorated empty bathroom </s>\", \"../data/train2014/COCO_train2014_000000318556.jpg\")            \n",
       " (\"<s> A panoramic view of a kitchen and all of its appliances </s>\", \"../data/train2014/COCO_train2014_000000116100.jpg\")   \n",
       " (\"<s> A blue and white bathroom with butterfly themed wall tiles </s>\", \"../data/train2014/COCO_train2014_000000318556.jpg\")\n",
       " (\"<s> A panoramic photo of a kitchen and dining room </s>\", \"../data/train2014/COCO_train2014_000000116100.jpg\")            \n",
       " (\"<s> A graffitied stop sign across the street from a red car  </s>\", \"../data/train2014/COCO_train2014_000000379340.jpg\")  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punc = \"!#%&()*+.,-/:;=?@[]^_`{|}~\"\n",
    "punctuation = [punc[i] for i in 1:length(punc)]\n",
    "\n",
    "NUM_SENTENCES = 5\n",
    "data = load_data(BASE_PATH,NUM_SENTENCES,punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captions = [d[1] for d in data]\n",
    "tokens = cat([tokenize(sentence) for sentence in captions]...,dims=1)\n",
    "vocab = unique(tokens)\n",
    "# Sort according to frequencies\n",
    "freqs = reverse(sort(collect(countmap(tokens)),by=x->x[2]))\n",
    "# Find top-k tokens\n",
    "K = 30\n",
    "top_k_tokens = [freqs[i][1] for i in 1:K]\n",
    "tokenized_captions = []\n",
    "for i in 1:length(captions)\n",
    "    sent_tokens = tokenize(captions[i])\n",
    "    for j in 1:length(sent_tokens)\n",
    "        sent_tokens[j] = !(sent_tokens[j] in top_k_tokens) ? \"<UNK>\" : sent_tokens[j]\n",
    "    end\n",
    "    push!(tokenized_captions,sent_tokens)\n",
    "end\n",
    "max_length_sentence = maximum([length(cap) for cap in tokenized_captions])\n",
    "# Pad the sequences\n",
    "for (i,cap) in enumerate(tokenized_captions)\n",
    "    if length(cap) < max_length_sentence\n",
    "        tokenized_captions[i] = [tokenized_captions[i]...,[\"<PAD>\" for i in 1:(max_length_sentence - length(cap))]...]\n",
    "    end\n",
    "end\n",
    "# Define the vocabulary\n",
    "vocab = [top_k_tokens...,\"<UNK>\",\"<PAD>\"]\n",
    "# Define mappings\n",
    "word2idx = Dict(word=>i for (i,word) in enumerate(vocab))\n",
    "idx2word = Dict(value=>key for (key,value) in word2idx)\n",
    "SEQ_LEN = max_length_sentence\n",
    "# Now - tokenized_captions contains the tokens for each caption in the form of an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Array{Any,1}:\n",
       " [\"<s>\", \"A\", \"<UNK>\", \"clean\", \"and\", \"well\", \"<UNK>\", \"<UNK>\", \"bathroom\", \"</s>\", \"<PAD>\", \"<PAD>\", \"<PAD>\"]\n",
       " [\"<s>\", \"A\", \"panoramic\", \"<UNK>\", \"of\", \"a\", \"kitchen\", \"and\", \"all\", \"of\", \"its\", \"appliances\", \"</s>\"]     \n",
       " [\"<s>\", \"A\", \"blue\", \"and\", \"<UNK>\", \"bathroom\", \"with\", \"<UNK>\", \"themed\", \"wall\", \"<UNK>\", \"</s>\", \"<PAD>\"] \n",
       " [\"<s>\", \"A\", \"panoramic\", \"photo\", \"of\", \"a\", \"kitchen\", \"and\", \"dining\", \"room\", \"</s>\", \"<PAD>\", \"<PAD>\"]   \n",
       " [\"<s>\", \"A\", \"graffitied\", \"stop\", \"sign\", \"across\", \"the\", \"street\", \"from\", \"a\", \"red\", \"car\", \"</s>\"]      "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "onehotword (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehotword(word) = Float32.(onehot(word2idx[word],1:length(vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Base.Iterators.PartitionIterator{UnitRange{Int64}}(1:5, 64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "mb_idxs = partition(1:length(data),BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "load_embedding_features (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Metalhead\n",
    "using JLD\n",
    "\n",
    "image_names = [d[2] for d in data]\n",
    "\n",
    "function extract_embedding_features(image_names)\n",
    "    # extract features from the images and save them to a file\n",
    "    vgg = VGG19() |> gpu\n",
    "    Flux.testmode!(vgg)\n",
    "    vgg = vgg.layers[1:end-3] |> gpu\n",
    "    \n",
    "    features = Dict()\n",
    "    for im_name in image_names\n",
    "        if im_name in keys(features)\n",
    "            continue\n",
    "        end\n",
    "        \n",
    "        img = Metalhead.preprocess(load(im_name)) |> gpu\n",
    "        out = vgg(img)\n",
    "        \n",
    "        features[im_name] = out |> cpu\n",
    "    end\n",
    "    \n",
    "    save(\"features.jld\",\"features\",features)\n",
    "end\n",
    "\n",
    "function load_embedding_features()\n",
    "    load(\"features.jld\")[\"features\"]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any,Any} with 3 entries:\n",
       "  \"../data/train2014/COCO_train2014_… => Float32[10.4405; 0.0; … ; 0.0; 1.86139]\n",
       "  \"../data/train2014/COCO_train2014_… => Float32[3.51554; 0.0; … ; 0.0; 0.0]\n",
       "  \"../data/train2014/COCO_train2014_… => Float32[0.0; 0.0; … ; 0.0; 0.0]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract_embedding_features(image_names)\n",
    "features = load_embedding_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_mb (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function get_mb(idx,features)\n",
    "    cap = tokenized_captions[idx]\n",
    "    img_names = image_names[idx]\n",
    "    \n",
    "    mb_captions = []\n",
    "    mb_features = []\n",
    "    mb_targets = []\n",
    "    \n",
    "    for i in 1:length(img_names)\n",
    "         push!(mb_features,features[img_names[i]])\n",
    "    end\n",
    "    \n",
    "    mb_features = hcat(mb_features...)\n",
    "    # Convert to - Array[SEQ_LEN] with each element - [V,BATCH_SIZE]\n",
    "    for i in 1:SEQ_LEN\n",
    "        # Extract and form a batch of each word in sequence\n",
    "        words = hcat([onehotword(sentence[i]) for sentence in cap]...)\n",
    "        \n",
    "        if i < SEQ_LEN\n",
    "            push!(mb_targets,hcat([onehotword(sentence[i + 1]) for sentence in cap]...))\n",
    "        else\n",
    "            push!(mb_targets,hcat([onehotword(\"<PAD>\") for sentence in cap]...))\n",
    "        end\n",
    "        \n",
    "        push!(mb_captions,words)\n",
    "    end\n",
    "    \n",
    "    (mb_captions,mb_features,mb_targets)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "zero_grad! (generic function with 1 method)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function nullify_grad!(p)\n",
    "  if typeof(p) <: TrackedArray\n",
    "    p.grad .= 0.0f0\n",
    "  end\n",
    "  return p\n",
    "end\n",
    "\n",
    "function zero_grad!(model)\n",
    "  model = mapleaves(nullify_grad!, model)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reset (generic function with 1 method)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EMBEDDING_DIM = 256\n",
    "HIDDEN_DIM = 512\n",
    "cnn_encoder = Chain(Dense(4096,EMBEDDING_DIM),x->relu.(x))\n",
    "embedding = Chain(Dense(length(vocab),EMBEDDING_DIM))\n",
    "rnn_decoder = Chain(LSTM(EMBEDDING_DIM,HIDDEN_DIM))\n",
    "decoder = Chain(Dense(HIDDEN_DIM,length(vocab)))\n",
    "\n",
    "function reset()\n",
    "    Flux.reset!(rnn_decoder.layers[1])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "zero_grad_models (generic function with 1 method)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function zero_grad_models()\n",
    "    zero_grad!(cnn_encoder)\n",
    "    zero_grad!(embedding)\n",
    "    zero_grad!(rnn_decoder)\n",
    "    zero_grad!(decoder)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "load_models (generic function with 1 method)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using BSON:@save,@load\n",
    "\n",
    "function save_models()\n",
    "    reset()\n",
    "    @save \"cnn_encoder.bson\" cnn_encoder\n",
    "    @save \"embedding.bson\" embedding\n",
    "    @save \"rnn_decoder.bson\" rnn_decoder\n",
    "    @save \"decoder.bson\" decoder\n",
    "end\n",
    "\n",
    "function load_models()\n",
    "    @load \"cnn_encoder.bson\" cnn_encoder\n",
    "    @load \"embedding.bson\" embedding\n",
    "    @load \"rnn_decoder.bson\" rnn_decoder\n",
    "    @load \"decoder.bson\" decoder\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_loss_val (generic function with 1 method)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function get_loss_val(mb_captions,mb_features,mb_targets)\n",
    "    reset()\n",
    "    lstm_inp = cnn_encoder(mb_features)\n",
    "    word_embeddings = embedding.(mb_captions)\n",
    "    lstm_out = rnn_decoder(lstm_inp)\n",
    "    predictions = softmax.(decoder.(rnn_decoder.(word_embeddings)))\n",
    "    sum(Flux.crossentropy.(predictions,mb_targets))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: ADAM(params) is deprecated; use ADAM(η::Float64) instead\n",
      "│   caller = top-level scope at In[140]:3\n",
      "└ @ Core In[140]:3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Global Step : 10\n",
      "Loss : 1.396667f0 (tracked)\n",
      "Saved Models!\n",
      "---Global Step : 20\n",
      "Loss : 1.1391783f0 (tracked)\n",
      "Saved Models!\n",
      "---Global Step : 30\n",
      "Loss : 1.0661407f0 (tracked)\n",
      "Saved Models!\n",
      "---Global Step : 40\n",
      "Loss : 1.0148447f0 (tracked)\n",
      "Saved Models!\n",
      "---Global Step : 50\n",
      "Loss : 0.9833323f0 (tracked)\n",
      "Saved Models!\n",
      "---Global Step : 60\n",
      "Loss : 0.9555775f0 (tracked)\n",
      "Saved Models!\n",
      "---Global Step : 70\n",
      "Loss : 0.9302694f0 (tracked)\n",
      "Saved Models!\n",
      "---Global Step : 80\n",
      "Loss : 0.9072114f0 (tracked)\n",
      "Saved Models!\n",
      "---Global Step : 90\n",
      "Loss : 0.8858993f0 (tracked)\n",
      "Saved Models!\n",
      "---Global Step : 100\n",
      "Loss : 0.8661209f0 (tracked)\n",
      "Saved Models!\n",
      "---Global Step : 110\n",
      "Loss : 0.8477492f0 (tracked)\n",
      "Saved Models!\n",
      "---Global Step : 120\n",
      "Loss : 0.83065426f0 (tracked)\n",
      "Saved Models!\n",
      "---Global Step : 130\n",
      "Loss : 0.8147495f0 (tracked)\n",
      "Saved Models!\n",
      "---Global Step : 140\n",
      "Loss : 0.7999724f0 (tracked)\n",
      "Saved Models!\n",
      "---Global Step : 150\n",
      "Loss : 0.7862482f0 (tracked)\n",
      "Saved Models!\n",
      "---Global Step : 160\n",
      "Loss : 0.7734897f0 (tracked)\n",
      "Saved Models!\n",
      "---Global Step : 170\n",
      "Loss : 0.7616192f0 (tracked)\n",
      "Saved Models!\n",
      "---Global Step : 180\n",
      "Loss : 0.75056887f0 (tracked)\n",
      "Saved Models!\n",
      "---Global Step : 190\n",
      "Loss : 0.74027246f0 (tracked)\n",
      "Saved Models!\n",
      "---Global Step : 200\n",
      "Loss : 0.7306763f0 (tracked)\n",
      "Saved Models!\n",
      "---Global Step : 210\n",
      "Loss : 0.7217285f0 (tracked)\n",
      "Saved Models!\n",
      "---Global Step : 220\n",
      "Loss : 0.71337736f0 (tracked)\n",
      "Saved Models!\n",
      "---Global Step : 230\n",
      "Loss : 0.70557415f0 (tracked)\n",
      "Saved Models!\n",
      "---Global Step : 240\n",
      "Loss : 0.6982777f0 (tracked)\n",
      "Saved Models!\n",
      "---Global Step : 250\n",
      "Loss : 0.69145036f0 (tracked)\n",
      "Saved Models!\n",
      "---Global Step : 260\n",
      "Loss : 0.6850583f0 (tracked)\n",
      "Saved Models!\n",
      "---Global Step : 270\n",
      "Loss : 0.67906845f0 (tracked)\n",
      "Saved Models!\n",
      "---Global Step : 280\n",
      "Loss : 0.67344904f0 (tracked)\n",
      "Saved Models!\n",
      "---Global Step : 290\n",
      "Loss : 0.66817194f0 (tracked)\n",
      "Saved Models!\n",
      "---Global Step : 300\n",
      "Loss : 0.66321313f0 (tracked)\n",
      "Saved Models!\n"
     ]
    }
   ],
   "source": [
    "model_params = params(params(cnn_encoder)...,params(embedding)...,params(rnn_decoder)...,params(decoder)...)\n",
    "lr = 1e-4\n",
    "opt = ADAM(model_params,lr)\n",
    "\n",
    "LOG_FREQUENCY = 10\n",
    "EPOCHS = 300\n",
    "SAVE_FREQUENCY = 10\n",
    "global_step = 1\n",
    "\n",
    "for epoch in 1:EPOCHS\n",
    "    for idx in mb_idxs\n",
    "        mb_captions,mb_features,mb_targets = get_mb(idx,features)\n",
    "        zero_grad_models()\n",
    "        Flux.back!(get_loss_val(mb_captions,mb_features,mb_targets))\n",
    "        opt()\n",
    "        global_step += 1\n",
    "        \n",
    "        if global_step % LOG_FREQUENCY == 0\n",
    "            println(\"---Global Step : $(global_step)\")\n",
    "            println(\"Loss : $(get_loss_val(mb_captions,mb_features,mb_targets))\")\n",
    "        end\n",
    "        \n",
    "        if global_step % SAVE_FREQUENCY == 0\n",
    "            save_models()\n",
    "            println(\"Saved Models!\")\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(Conv((3, 3), 3=>64, NNlib.relu), Conv((3, 3), 64=>64, NNlib.relu), getfield(Metalhead, Symbol(\"##42#48\"))(), Conv((3, 3), 64=>128, NNlib.relu), Conv((3, 3), 128=>128, NNlib.relu), getfield(Metalhead, Symbol(\"##43#49\"))(), Conv((3, 3), 128=>256, NNlib.relu), Conv((3, 3), 256=>256, NNlib.relu), Conv((3, 3), 256=>256, NNlib.relu), Conv((3, 3), 256=>256, NNlib.relu), getfield(Metalhead, Symbol(\"##44#50\"))(), Conv((3, 3), 256=>512, NNlib.relu), Conv((3, 3), 512=>512, NNlib.relu), Conv((3, 3), 512=>512, NNlib.relu), Conv((3, 3), 512=>512, NNlib.relu), getfield(Metalhead, Symbol(\"##45#51\"))(), Conv((3, 3), 512=>512, NNlib.relu), Conv((3, 3), 512=>512, NNlib.relu), Conv((3, 3), 512=>512, NNlib.relu), Conv((3, 3), 512=>512, NNlib.relu), getfield(Metalhead, Symbol(\"##46#52\"))(), getfield(Metalhead, Symbol(\"##47#53\"))(), Dense(25088, 4096, NNlib.relu), Dropout{Float32}(0.5f0, false), Dense(4096, 4096, NNlib.relu))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg = VGG19() |> gpu\n",
    "Flux.testmode!(vgg)\n",
    "vgg = vgg.layers[1:end-3] |> gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sample (generic function with 1 method)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function sample(image_path)\n",
    "    img = Metalhead.preprocess(load(image_path)) |> gpu\n",
    "    features = vgg(img) |> cpu\n",
    "    \n",
    "    reset()\n",
    "    prev_word = \"<s>\"\n",
    "    lstm_inp = cnn_encoder(features)\n",
    "    lstm_out = rnn_decoder(lstm_inp)\n",
    "    output = \"\"\n",
    "    \n",
    "    for i in 1:15\n",
    "        output = string(output,\" \",prev_word)\n",
    "        if prev_word == \"</s>\"\n",
    "            break\n",
    "        end\n",
    "        word_embeddings = embedding(onehotword(prev_word))\n",
    "        predictions = softmax(decoder(rnn_decoder(word_embeddings)))\n",
    "        next_word = idx2word[Flux.argmax(predictions)[1]]\n",
    "        prev_word = next_word\n",
    "    end\n",
    "    \n",
    "    output\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" <s> A blue and <UNK> bathroom with <UNK> themed wall <UNK> </s>\""
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample(image_names[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset()\n",
    "@save \"t.bson\" rnn_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = Chain(LSTM(2,3))\n",
    "@save \"t.bson\" m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Any[Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Float32[1.0 1.0 … 1.0 1.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 1.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 1.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 1.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 1.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Float32[0.0 0.0 … 0.0 0.0; 1.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 1.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 1.0 0.0 … 0.0 0.0], Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 1.0 0.0 … 1.0 0.0], Float32[0.0 0.0 … 0.0 0.0; 0.0 1.0 … 0.0 1.0; … ; 0.0 0.0 … 0.0 0.0; 1.0 0.0 … 1.0 0.0]], Float32[3.51554 10.4405 … 10.4405 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 1.86139 … 1.86139 0.0], Any[Float32[1.0 1.0 … 1.0 1.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 1.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 1.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 1.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 1.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Float32[0.0 0.0 … 0.0 0.0; 1.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 1.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 1.0 0.0 … 0.0 0.0], Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 1.0 0.0 … 1.0 0.0], Float32[0.0 0.0 … 0.0 0.0; 0.0 1.0 … 0.0 1.0; … ; 0.0 0.0 … 0.0 0.0; 1.0 0.0 … 1.0 0.0], Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 1.0 1.0 … 1.0 1.0]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mb_captions,mb_features,mb_targets = get_mb(collect(mb_idxs)[1],features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13-element Array{CuArray{Float32,2},1}:\n",
       " [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       " [1.0 1.0 … 1.0 1.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       " [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 1.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       " [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 1.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       " [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       " [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       " [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 1.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       " [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 1.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       " [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       " [0.0 0.0 … 0.0 0.0; 1.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       " [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 1.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 1.0 0.0 … 0.0 0.0]\n",
       " [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 1.0 0.0 … 1.0 0.0]\n",
       " [0.0 0.0 … 0.0 0.0; 0.0 1.0 … 0.0 1.0; … ; 0.0 0.0 … 0.0 0.0; 1.0 0.0 … 1.0 0.0]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu.(mb_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096×5 CuArray{Float32,2}:\n",
       "  3.51554  10.4405    3.51554  10.4405    0.0    \n",
       "  0.0       0.0       0.0       0.0       0.0    \n",
       "  0.0       0.0       0.0       0.0       0.0    \n",
       "  0.0       0.0       0.0       0.0       0.0    \n",
       " 10.7507    0.0      10.7507    0.0       0.0    \n",
       "  0.0       6.03384   0.0       6.03384  10.7011 \n",
       "  0.0       0.0       0.0       0.0       0.0    \n",
       "  0.0       0.0       0.0       0.0       5.73202\n",
       "  0.0       0.0       0.0       0.0       0.0    \n",
       "  0.0       0.0       0.0       0.0       0.0    \n",
       "  2.32066   0.0       2.32066   0.0       0.0    \n",
       "  0.0       0.0       0.0       0.0       0.0    \n",
       " 10.5443    0.0      10.5443    0.0       0.0    \n",
       "  ⋮                                              \n",
       "  0.0       0.0       0.0       0.0       0.0    \n",
       "  0.0       0.0       0.0       0.0       0.0    \n",
       "  0.0       0.0       0.0       0.0       0.0    \n",
       "  0.0       0.0       0.0       0.0       0.0    \n",
       "  5.90421   0.0       5.90421   0.0       0.0    \n",
       "  0.0       0.0       0.0       0.0       0.0    \n",
       "  0.0       0.0       0.0       0.0       0.0    \n",
       "  0.0       0.0       0.0       0.0       0.0    \n",
       "  0.0       0.0       0.0       0.0       1.01691\n",
       "  7.19985   0.0       7.19985   0.0       0.0    \n",
       "  0.0       0.0       0.0       0.0       0.0    \n",
       "  0.0       1.86139   0.0       1.86139   0.0    "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu(mb_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13-element Array{CuArray{Float32,2},1}:\n",
       " [1.0 1.0 … 1.0 1.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       " [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 1.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       " [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 1.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       " [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       " [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       " [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 1.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       " [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 1.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       " [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       " [0.0 0.0 … 0.0 0.0; 1.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       " [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 1.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 1.0 0.0 … 0.0 0.0]\n",
       " [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 1.0 0.0 … 1.0 0.0]\n",
       " [0.0 0.0 … 0.0 0.0; 0.0 1.0 … 0.0 1.0; … ; 0.0 0.0 … 0.0 0.0; 1.0 0.0 … 1.0 0.0]\n",
       " [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 1.0 1.0 … 1.0 1.0]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu.(mb_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.1.0",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
